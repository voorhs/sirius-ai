- Лекция 1 (евгений): Основы глубинного обучения. Полносвязаные слои. Обратное распространение ошибки.
- Семинар 1.1 (илья): Основы PyTorch: тензоры, backprop.
- Семинар 1.2 (саша): Цикл обучения. Примеры с torch-циклами для решения разных задач DL (табличные, изображения, регрессия, классификация).
- Домашка на простейший цикл обучения в pytorch (у нас есть готовая, заполнение ноутбука)

- Лекция 2 (саша): Задачи компьютерного зрения: классификация, детекция, сегментация, поиск. Предобработка: дилатация и проч аугментации. Свёртки и свёрточные сети: VGG, Resnet, Unet.
- Семинар (2 шт., пока на уровне идеи): Дообучение свёрточных сетей. Использование моделей из HuggingFace и возможно других хабов. Файнтюн моделей.
- Домашка: взять модель с HF, заинферить и показать результаты (в формате заполнения ноутбука, его надо сделать)

- Лекция 3 (илья): Работа с последовательностями. Векторные представления слов. Кратко о рекуррентных сетях. Архитектура Трансформер. Предобученные трансформеры. Применение к CV. Мультимодальные модели (CLIP).
- Семинар 3.1(саша): ASR с помощью Whisper (потому что тоже трансформер + полезно). Git: version-control, commit, branch.
- Семинар 3.2 (илья): word2vec (gensim), hf transformers: BERT, GPT. Промт инжиниринг, LLM HTTP API.
- Домашка: общение с LLM в аудио формате ASR + TTS (тоже заполнение ноутбука, надо сделать)

- Лекция 4 (саша): Диффузионные модели. Stable Diffusion. ControlNet. Перенос стиля. (материалы есть)
- Семинар 1 (саша): Файнтюн SD для чайников.
- Семинар 2 (илья): aiogram, streamlit