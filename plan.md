- Лекция 1 (евгений): Основы глубинного обучения (с инженерной точки зрения как минимизация некоторой функции потерь). Полносвязаные слои. Обратное распространение ошибки. Тензоры, матричное умножение.
- Семинар 1.1 (илья): Основы PyTorch: тензоры, backprop. Слои pytorch
- Семинар 1.2 (саша): Цикл обучения. Примеры с torch-циклами для решения разных задач DL (табличные, изображения, регрессия, классификация).
- Домашка:
    - простейший цикл обучения в pytorch
    - операции с тензорами: создание, перенесение

- Лекция 2 (саша): Задачи компьютерного зрения: классификация, детекция, сегментация, поиск. Предобработка: дилатация и проч аугментации. Свёртки и свёрточные сети: VGG, Resnet, Unet.
- Семинар 1.1 (саша): Дообучение свёрточных сетей (пример с ResNet, у ноутбука четкий посыл)
- Семинар 1.2 (илья) Использование моделей из HuggingFace для задач CV.
- Домашка: повторить действия из семинара 1.2 на другом датасете и на другой задаче

- Лекция 3 (илья):
    - Основы NLP (токенизация, BOW)
    - Эмбединги слов (w2v)
    - Кратко о рекуррентных сетях (добавление зависимостей между словами + обновление репрезентаций)
    - Внимание в RNN (более крутое добавление зависимостей между словами)
    - Самовнимание
    - Предобученные трансформеры (BERT, LLM). Применение к CV. Мультимодальные модели (CLIP).
- Семинар 3.1(саша): ASR с помощью Whisper (потому что тоже трансформер + полезно). Git: version-control, commit, branch.
- Семинар 3.2 (илья): word2vec (gensim), hf transformers: BERT, GPT. Промт инжиниринг, LLM HTTP API.
- Домашка: общение с LLM в аудио формате ASR + TTS (тоже заполнение ноутбука, надо сделать)

- Лекция 4 (саша): Диффузионные модели. Stable Diffusion. ControlNet. Перенос стиля. (материалы есть)
- Семинар 1 (саша): pandas, matplotlib, seaborn, plotly
- Семинар 2 (илья): streamlit, aiogram